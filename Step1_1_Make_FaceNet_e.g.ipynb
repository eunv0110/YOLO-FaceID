{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcionhVJzd5r"
   },
   "source": [
    "# **Make Pretrained-Model FaceNet !**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6qgvZMSYcoX"
   },
   "source": [
    "* 구글 드라이브 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imfft4dGGJ2E"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPngJ_nwZPRC"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/project4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPwDW6e_Y0Fa"
   },
   "source": [
    "* 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4dS7tW-Zwrx"
   },
   "outputs": [],
   "source": [
    "## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n",
    "!pip install keras-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OntGw5H-C3q"
   },
   "source": [
    "#### 1) 본인 얼굴 이미지 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veax9Lje-CzS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trmm4ozP-C60"
   },
   "outputs": [],
   "source": [
    "data_myFace = os.path.join(path, 'Datasets/Keras/my_face_12000.zip')\n",
    "data_myFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9wNE6-chAih"
   },
   "outputs": [],
   "source": [
    "## Colab에 생성할 본인 얼굴 폴더 경로\n",
    "extract_folder = '/content/my_face'\n",
    "\n",
    "## 위의 경로에 폴더가 없을 때 생성\n",
    "if not os.path.exists(extract_folder) :\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "## 위의 경로에 압축을 해제\n",
    "with zipfile.ZipFile(data_myFace, 'r') as zip_ref :\n",
    "    file_list = zip_ref.namelist()\n",
    "\n",
    "    for f in file_list :\n",
    "        if not f.endswith('/') and f.lower().endswith('.jpg') :\n",
    "            file_name = os.path.basename(f)\n",
    "\n",
    "            if not file_name.startswith('._') :\n",
    "                d_path = os.path.join(extract_folder, file_name)\n",
    "\n",
    "                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n",
    "                    target.write(source.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtpBNHCehXWD"
   },
   "outputs": [],
   "source": [
    "## 생성된 본인 얼굴 이미지 데이터 폴더 안의 이미지 수\n",
    "len(os.listdir(extract_folder) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCDldok5ySsg"
   },
   "source": [
    "#### 2) 다른 얼굴 이미지 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4JpqpxAySpc"
   },
   "outputs": [],
   "source": [
    "data_other = path + '/Keras/lfw-deepfunneled.zip'\n",
    "data_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwRwu_AasZzu"
   },
   "outputs": [],
   "source": [
    "## Colab에 생성할 다른 얼굴 폴더 경로\n",
    "extract_folder = '/content/other_face'\n",
    "\n",
    "## 위의 경로에 폴더가 없을 때 생성\n",
    "if not os.path.exists(extract_folder) :\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "## 위의 경로에 압축을 해제\n",
    "with zipfile.ZipFile(data_other, 'r') as zip_ref :\n",
    "    file_list = zip_ref.namelist()\n",
    "\n",
    "    for f in file_list :\n",
    "        if not f.endswith('/') and f.lower().endswith('.jpg') :\n",
    "            file_name = os.path.basename(f)\n",
    "\n",
    "            if not file_name.startswith('._') :\n",
    "                d_path = os.path.join(extract_folder, file_name)\n",
    "\n",
    "                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n",
    "                    target.write(source.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meIbdjnPySmd"
   },
   "outputs": [],
   "source": [
    "## 생성된 다른 사람 얼굴 이미지 데이터 폴더 안의 이미지 수\n",
    "len(os.listdir(extract_folder) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPI-FA1iiPoc"
   },
   "source": [
    "#### 1) 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IINQdzBhUtqV"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtFbWnNZlgtT"
   },
   "outputs": [],
   "source": [
    "## image_dataset_from_directory를 사용하기 위해 Colab에 폴더 생성\n",
    "\n",
    "## 생성될 폴더의 경로\n",
    "tr_data = '/content/tr_data'\n",
    "te_data = '/content/te_data'\n",
    "\n",
    "## 폴더가 존재하지 않을 때 폴더를 생성\n",
    "if not os.path.exists(tr_data) :\n",
    "    os.makedirs(tr_data)\n",
    "\n",
    "if not os.path.exists(te_data) :\n",
    "    os.makedirs(te_data)\n",
    "\n",
    "## 폴더 생성 확인\n",
    "print(os.path.exists(tr_data) )\n",
    "print(os.path.exists(te_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZkhJC1dlgns"
   },
   "outputs": [],
   "source": [
    "## Keras의 image_dataset_from_directory를 사용하기 위해 Colab에 하위 폴더 생성\n",
    "\n",
    "## 생성될 폴더에 대한 하위 폴더 생성\n",
    "class_names = ['my', 'other']\n",
    "\n",
    "for cn in class_names :\n",
    "    temp = os.path.join(tr_data, cn)\n",
    "\n",
    "    if not os.path.exists( temp ) :\n",
    "        os.makedirs(temp)\n",
    "\n",
    "    ## 폴더 생성 확인\n",
    "    print(os.path.exists(temp))\n",
    "\n",
    "for cn in class_names :\n",
    "    temp = os.path.join(te_data, cn)\n",
    "\n",
    "    if not os.path.exists( temp ) :\n",
    "        os.makedirs(temp)\n",
    "\n",
    "    ## 폴더 생성 확인\n",
    "    print(os.path.exists(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QsrKxgXlggh"
   },
   "outputs": [],
   "source": [
    "## 본인 얼굴 데이터가 있는 폴더 경로의 파일 전체를 정렬하여 리스트화\n",
    "img_list_my = sorted(glob.glob('/content/my_face/*',))\n",
    "\n",
    "## 다른 얼굴 데이터가 있는 폴더 경로의 파일 전체를 정렬하여 리스트화\n",
    "img_list_other = sorted(glob.glob('/content/other_face/*'))\n",
    "\n",
    "## 이미지 갯수 확인\n",
    "len(img_list_my), len(img_list_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tu7gBCzOt3j8"
   },
   "outputs": [],
   "source": [
    "## 얼굴 데이터를 Training set, Test set으로 분할하기 위한 사전 작업\n",
    "## 분할 재현성을 위한 난수 고정\n",
    "random.seed(2024)\n",
    "random.shuffle(img_list_my)\n",
    "random.shuffle(img_list_other)\n",
    "\n",
    "img_list_my[:5], img_list_other[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRItB6YgwG__"
   },
   "outputs": [],
   "source": [
    "## Test set의 비율 설정\n",
    "test_size = 0.2\n",
    "\n",
    "## 나의 얼굴 파일 리스트와 다른 얼굴 파일 리스트에 대한 반복문\n",
    "for i_l in [img_list_my, img_list_other] :\n",
    "    ## 리스트의 길이 체크\n",
    "    # list_len = len(i_l)\n",
    "    list_len = 11000  ## 예시 파일의 이미지 갯수가 맞지 않아서 11000개까지만 사용\n",
    "    ## 데이터 분할을 위한 인덱스 설정\n",
    "    split_idx = int(list_len * (1 - test_size) )\n",
    "\n",
    "    ## 인덱스를 이용해 상위 리스트를 Training set, Test set 2가지로 세분화\n",
    "    list_tr = i_l[ : split_idx]\n",
    "    list_te = i_l[split_idx : list_len]\n",
    "\n",
    "    ## 현재 리스트가 나의 얼굴 파일 리스트와 같다면\n",
    "    if i_l == img_list_my :\n",
    "        ## \"나의 얼굴 파일 리스트\"의 파일을 Training set 폴더 안의 \"나의 얼굴 폴더\"로 복사\n",
    "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
    "        for file_path in list_tr :\n",
    "            f_name = file_path.split('/')\n",
    "            shutil.copy(src=file_path,\n",
    "                        dst=tr_data+'/my/'+f_name[-1]\n",
    "                        )\n",
    "            print(f'파일 이동 완료 : {f_name[-1]}')\n",
    "\n",
    "        ## \"나의 얼굴 파일 리스트\"의 파일을 Test set 폴더 안의 \"나의 얼굴 폴더\"로 복사\n",
    "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
    "        for file_path in list_te :\n",
    "            f_name = file_path.split('/')\n",
    "            shutil.copy(src=file_path,\n",
    "                        dst=te_data+'/my/'+f_name[-1]\n",
    "                        )\n",
    "            print(f'파일 이동 완료 : {f_name[-1]}')\n",
    "\n",
    "    ## 현재 리스트가 \"나의 얼굴 파일 리스트\"가 아니라면 (즉, \"다른 사람 얼굴 파일 리스트\"라면)\n",
    "    else :\n",
    "        ## \"다른 사람 얼굴 파일 리스트\"의 파일을 Training set 폴더 안의 \"다른 사람 얼굴 폴더\"로 복사\n",
    "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
    "        for file_path in list_tr :\n",
    "            f_name = file_path.split('/')\n",
    "            shutil.copy(src=file_path,\n",
    "                        dst=tr_data+'/other/'+f_name[-1],\n",
    "                        )\n",
    "            print(f'파일 이동 완료 : {f_name[-1]}')\n",
    "\n",
    "        ## \"다른 사람 얼굴 파일 리스트\"의 파일을 Test set 폴더 안의 \"다른 사람 얼굴 폴더\"로 복사\n",
    "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
    "        for file_path in list_te :\n",
    "            f_name = file_path.split('/')\n",
    "            shutil.copy(src=file_path,\n",
    "                        dst=te_data+'/other/'+f_name[-1]\n",
    "                        )\n",
    "            print(f'파일 이동 완료 : {f_name[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdesufJet3pj"
   },
   "outputs": [],
   "source": [
    "## \"본인 얼굴\"에 대한 파일 리스트의 상위 5개 조회\n",
    "img_list_my[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3nRR3flt3sa"
   },
   "outputs": [],
   "source": [
    "## 위의 5개 파일이 image_dataset_from_directory에 맞춰 생성한 경로에 알맞게 있는지 확인\n",
    "## \"본인 얼굴\"에 대한 파일 리스트를 정렬한 후, 8:2로 나누었기 때문에 위의 상위 5개는 반드시 Training set의 \"나의 얼굴\" 폴더 안에 있어야 한다.\n",
    "\n",
    "print(os.path.exists('/content/tr_data/my/my_face_6786.jpg') )\n",
    "print(os.path.exists('/content/tr_data/my/my_face_2409.jpg') )\n",
    "print(os.path.exists('/content/tr_data/my/my_face_4048.jpg') )\n",
    "print(os.path.exists('/content/tr_data/my/my_face_8427.jpg') )\n",
    "print(os.path.exists('/content/tr_data/my/my_face_2278.jpg') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4xnDKW3twiZ"
   },
   "outputs": [],
   "source": [
    "## 다른 경로에 잘못 복사되었는지 확인\n",
    "\n",
    "print(os.path.exists('/content/tr_data/other/my_face_6786.jpg') )\n",
    "print(os.path.exists('/content/tr_data/other/my_face_2409.jpg') )\n",
    "print(os.path.exists('/content/tr_data/other/my_face_4048.jpg') )\n",
    "print(os.path.exists('/content/tr_data/other/my_face_8427.jpg') )\n",
    "print(os.path.exists('/content/tr_data/other/my_face_2278.jpg') )\n",
    "\n",
    "print(os.path.exists('/content/te_data/my/my_face_6786.jpg') )\n",
    "print(os.path.exists('/content/te_data/my/my_face_2409.jpg') )\n",
    "print(os.path.exists('/content/te_data/my/my_face_4048.jpg') )\n",
    "print(os.path.exists('/content/te_data/my/my_face_8427.jpg') )\n",
    "print(os.path.exists('/content/te_data/my/my_face_2278.jpg') )\n",
    "\n",
    "print(os.path.exists('/content/te_data/other/my_face_6786.jpg') )\n",
    "print(os.path.exists('/content/te_data/other/my_face_2409.jpg') )\n",
    "print(os.path.exists('/content/te_data/other/my_face_4048.jpg') )\n",
    "print(os.path.exists('/content/te_data/other/my_face_8427.jpg') )\n",
    "print(os.path.exists('/content/te_data/other/my_face_2278.jpg') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gLUXyvVt3vG"
   },
   "outputs": [],
   "source": [
    "print('Training data의 my_face 이미지 수 : ', len(os.listdir('/content/tr_data/my')))\n",
    "print('Training data의 other_face 이미지 수 : ', len(os.listdir('/content/tr_data/other')))\n",
    "\n",
    "print('Test data의 my_face 이미지 수 : ', len(os.listdir('/content/te_data/my')))\n",
    "print('Test data의 other_face 이미지 수 : ', len(os.listdir('/content/te_data/other')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbKoJ7sqoGKe"
   },
   "source": [
    "#### 2) **특정 함수** 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2yqpVM0HryP"
   },
   "outputs": [],
   "source": [
    "## Training set 데이터 폴더를 데이터셋화\n",
    "## 이 과정에서 Validation set도 생성\n",
    "tr_idfd, val_idfd = image_dataset_from_directory(tr_data,                    ## Training 폴더 경로\n",
    "                                                 class_names=['other','my'], ## 클래스 순서 지정\n",
    "                                                 batch_size=32,              ## 이미지 덩어리 단위\n",
    "                                                 image_size=(160,160),       ## 이미지 리사이즈\n",
    "                                                 shuffle=True,               ## 섞어야 올바르게 분할됨\n",
    "                                                 seed=2024,                  ## 재현성\n",
    "                                                 validation_split=0.3,       ## 데이터 스플릿 비율\n",
    "                                                 subset='both',              ## 데이터셋 나눔 방식\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvHXK3B-Ij3X"
   },
   "outputs": [],
   "source": [
    "## Test set 데이터 폴더를 데이터셋화\n",
    "te_idfd = image_dataset_from_directory(te_data,                    ## Test 폴더 경로\n",
    "                                       class_names=['other','my'], ## 클래스 순서 지정\n",
    "                                       batch_size=32,              ## 이미지 덩어리 단위\n",
    "                                       image_size=(160,160),       ## 이미지 리사이즈\n",
    "                                       shuffle=True,               ## 섞어야 올바르게 분할됨\n",
    "                                       seed=2024                   ## 재현성\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPafWinHDI6K"
   },
   "outputs": [],
   "source": [
    "## 위에서 만든 이미지 데이터 덩어리가 몇 개인지 확인\n",
    "len(tr_idfd), len(val_idfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pbJTbYA1dN-"
   },
   "source": [
    "#### 3) 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGBzIEeR1fZe"
   },
   "outputs": [],
   "source": [
    "def rescale(image, label) :\n",
    "    image = image / 255\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqM0hsiF3jsi"
   },
   "outputs": [],
   "source": [
    "tr_idfd_rescale = tr_idfd.map(rescale)\n",
    "val_idfd_rescale = val_idfd.map(rescale)\n",
    "te_idfd_rescale = te_idfd.map(rescale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEhBeJsarhxh"
   },
   "source": [
    "### (1) FaceNet 구조 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jr2hiBBuDL_"
   },
   "source": [
    "#### 1) 모델 구조 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZ3gbjSFyQfK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers import BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers import Lambda, Concatenate, add\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.saving import register_keras_serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33zdBJ9B_qhO"
   },
   "outputs": [],
   "source": [
    "## 3.6.0.dev2024100303 OK\n",
    "## 3.6.0 dev2024101103\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFMvcMGUyQb_"
   },
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "def scaling(x, scale):\n",
    "    return x * scale\n",
    "\n",
    "@register_keras_serializable()\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              strides=1,\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              use_bias=False,\n",
    "              name=None):\n",
    "    x = Conv2D(filters,\n",
    "               kernel_size,\n",
    "               strides=strides,\n",
    "               padding=padding,\n",
    "               use_bias=use_bias,\n",
    "               name=name)(x)\n",
    "    if not use_bias:\n",
    "        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "        bn_name = _generate_layer_name('BatchNorm', prefix=name)\n",
    "        x = BatchNormalization(axis=bn_axis, momentum=0.995, epsilon=0.001,\n",
    "                               scale=False, name=bn_name)(x)\n",
    "    if activation is not None:\n",
    "        ac_name = _generate_layer_name('Activation', prefix=name)\n",
    "        x = Activation(activation, name=ac_name)(x)\n",
    "    return x\n",
    "\n",
    "@register_keras_serializable()\n",
    "def _generate_layer_name(name, branch_idx=None, prefix=None):\n",
    "    if prefix is None:\n",
    "        return None\n",
    "    if branch_idx is None:\n",
    "        return '_'.join((prefix, name))\n",
    "    return '_'.join((prefix, 'Branch', str(branch_idx), name))\n",
    "\n",
    "@register_keras_serializable()\n",
    "def _inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    if block_idx is None:\n",
    "        prefix = None\n",
    "    else:\n",
    "        prefix = '_'.join((block_type, str(block_idx)))\n",
    "    name_fmt = partial(_generate_layer_name, prefix=prefix)\n",
    "\n",
    "    if block_type == 'Block35':\n",
    "        branch_0 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 32, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "        branch_2 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3, name=name_fmt('Conv2d_0c_3x3', 2))\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "    elif block_type == 'Block17':\n",
    "        branch_0 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 128, [1, 7], name=name_fmt('Conv2d_0b_1x7', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 128, [7, 1], name=name_fmt('Conv2d_0c_7x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    elif block_type == 'Block8':\n",
    "        branch_0 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [1, 3], name=name_fmt('Conv2d_0b_1x3', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [3, 1], name=name_fmt('Conv2d_0c_3x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    else:\n",
    "        raise ValueError('Unknown Inception-ResNet block type. '\n",
    "                         'Expects \"Block35\", \"Block17\" or \"Block8\", '\n",
    "                         'but got: ' + str(block_type))\n",
    "\n",
    "    mixed = Concatenate(axis=channel_axis, name=name_fmt('Concatenate'))(branches)\n",
    "    up = conv2d_bn(mixed,\n",
    "                #    K.int_shape(x)[channel_axis],\n",
    "                   x.shape[channel_axis],\n",
    "                   1,\n",
    "                   activation=None,\n",
    "                   use_bias=True,\n",
    "                   name=name_fmt('Conv2d_1x1'))\n",
    "    up = Lambda(scaling,\n",
    "                # output_shape=K.int_shape(up)[1:],\n",
    "                output_shape=up.shape[1:],\n",
    "                arguments={'scale': scale})(up)\n",
    "    x = add([x, up])\n",
    "    if activation is not None:\n",
    "        x = Activation(activation, name=name_fmt('Activation'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgI-eWQgyQZP"
   },
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "def InceptionResNetV1(input_shape=(160, 160, 3),\n",
    "                      classes=128,\n",
    "                      dropout_keep_prob=0.8,\n",
    "                      weights_path=None):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = conv2d_bn(inputs, 32, 3, strides=2, padding='valid', name='Conv2d_1a_3x3')\n",
    "    x = conv2d_bn(x, 32, 3, padding='valid', name='Conv2d_2a_3x3')\n",
    "    x = conv2d_bn(x, 64, 3, name='Conv2d_2b_3x3')\n",
    "    x = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n",
    "    x = conv2d_bn(x, 80, 1, padding='valid', name='Conv2d_3b_1x1')\n",
    "    x = conv2d_bn(x, 192, 3, padding='valid', name='Conv2d_4a_3x3')\n",
    "    x = conv2d_bn(x, 256, 3, strides=2, padding='valid', name='Conv2d_4b_3x3')\n",
    "\n",
    "    # 5x Block35 (Inception-ResNet-A block):\n",
    "    for block_idx in range(1, 6):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.17,\n",
    "                                    block_type='Block35',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 6a (Reduction-A block):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_6a')\n",
    "    branch_0 = conv2d_bn(x,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1, 192, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 2))(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_6a')(branches)\n",
    "\n",
    "    # 10x Block17 (Inception-ResNet-B block):\n",
    "    for block_idx in range(1, 11):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.1,\n",
    "                                    block_type='Block17',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_7a')\n",
    "    branch_0 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 0))\n",
    "    branch_0 = conv2d_bn(branch_0,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_2 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "    branch_2 = conv2d_bn(branch_2,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 2))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 3))(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_7a')(branches)\n",
    "\n",
    "    # 5x Block8 (Inception-ResNet-C block):\n",
    "    for block_idx in range(1, 6):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.2,\n",
    "                                    block_type='Block8',\n",
    "                                    block_idx=block_idx)\n",
    "    x = _inception_resnet_block(x,\n",
    "                                scale=1.,\n",
    "                                activation=None,\n",
    "                                block_type='Block8',\n",
    "                                block_idx=6)\n",
    "\n",
    "    # Classification block\n",
    "    x = GlobalAveragePooling2D(name='AvgPool')(x)\n",
    "    x = Dropout(1.0 - dropout_keep_prob, name='Dropout')(x)\n",
    "    # Bottleneck\n",
    "    x = Dense(classes, use_bias=False, name='Bottleneck')(x)\n",
    "    bn_name = _generate_layer_name('BatchNorm', prefix='Bottleneck')\n",
    "    x = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False,\n",
    "                           name=bn_name)(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs, x, name='inception_resnet_v1')\n",
    "    if weights_path is not None:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPQVI80cyQWK"
   },
   "outputs": [],
   "source": [
    "## FaceNet 구조 생성 코드\n",
    "facenet_model = InceptionResNetV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUtXVTIJugQL"
   },
   "outputs": [],
   "source": [
    "## FaceNet 구조의 전체 레이어 길이\n",
    "len(facenet_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ci_WZVvAyQTM"
   },
   "outputs": [],
   "source": [
    "## FaceNet 전체 구조 확인\n",
    "facenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UfZ2ZjVBKPq"
   },
   "source": [
    "#### 2) 모델에 가중치 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeF72aRXyQQO"
   },
   "outputs": [],
   "source": [
    "## FaceNet 가중치 파일 경로 설정\n",
    "weights_path = os.path.join('Datasets/Keras/facenet_model_weights.npz' )\n",
    "weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xrzp9pu0yQNW"
   },
   "outputs": [],
   "source": [
    "## 가중치 파일 불러오기\n",
    "loaded_weights = np.load(weights_path)\n",
    "\n",
    "loaded_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6p8OaqDQyQKb"
   },
   "outputs": [],
   "source": [
    "## FaceNet 각 레이어에 가중치 적용\n",
    "facenet_model.set_weights([loaded_weights[key] for key in loaded_weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ji08O1bBmU1"
   },
   "source": [
    "#### 3) 모델의 가중치 업데이트 방지 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_HW-n6qory5"
   },
   "outputs": [],
   "source": [
    "## FaceNet 전체 레이어에서 마지막 4개의 레이어 확인\n",
    "facenet_model.layers[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl14ADvFBmRc"
   },
   "outputs": [],
   "source": [
    "## FaceNet 전체 레이어에서 마지막 4개의 레이어에만 가중치 업데이트 적용\n",
    "for l in facenet_model.layers[:-4] :\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSZ6BywVBsES"
   },
   "source": [
    "### (2) 모델 구조 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj2q7vebwpky"
   },
   "source": [
    "#### 1) 추가 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MflXlU6LBmMV"
   },
   "outputs": [],
   "source": [
    "## FaceNet 모델에 이진 분류용 레이어 하나 추가\n",
    "K.clear_session()\n",
    "\n",
    "custom_model = keras.models.Sequential()\n",
    "\n",
    "custom_model.add(facenet_model)\n",
    "custom_model.add(Dense(1, activation='sigmoid') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDqse1MHx9mC"
   },
   "outputs": [],
   "source": [
    "custom_model.summary() ## keras-nightly로는 정상 작동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROWm9jllAFec"
   },
   "outputs": [],
   "source": [
    "custom_model.compile(optimizer='adam',\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['accuracy', 'precision', 'recall']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iEtx6mJxaCI"
   },
   "source": [
    "### (1) 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVKBjLf4xeah"
   },
   "source": [
    "* **세부 요구사항**\n",
    "    - 모델 구조를 잘 변형하였다면, 학습도 진행해야 합니다.\n",
    "        - Keras에서 지원하는 다양한 함수를 사용하세요.\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9P5R2_Tp0SGV"
   },
   "source": [
    "#### 1) 학습에 유용한 함수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuOXlSGrxclb"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10XBWir9yCdz"
   },
   "outputs": [],
   "source": [
    "## 얼리스토핑 설정\n",
    "es = EarlyStopping(patience=4, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84-AbpGw0WlD"
   },
   "source": [
    "#### 2) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwyY85hqyC-L"
   },
   "outputs": [],
   "source": [
    "## 모델 학습\n",
    "custom_model.fit(tr_idfd, validation_data=val_idfd,\n",
    "                 epochs=100, verbose=1,\n",
    "                 class_weight={0:1, 1:2}, ## 클래스 1에 대해 가중치를 더 주려는 의도\n",
    "                 callbacks=[es]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsI5xF6ZyDCB"
   },
   "source": [
    "### (2) 모델 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlUaGjUDyDFI"
   },
   "source": [
    "* **세부 요구사항**\n",
    "    - 학습된 모델의 성능을 확인해보세요.\n",
    "        - 임계값 조절, 클래스 가중치 부여 등으로 모델의 성능을 높여보세요.\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - keras, sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUfy6T3-0up8"
   },
   "source": [
    "#### 1) 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adRp8lItyDIJ"
   },
   "outputs": [],
   "source": [
    "## image_dataset_from_directory로 만든 Test set로 예측값 생성\n",
    "y_pred = custom_model.predict(te_idfd)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5enpWwrA2EMa"
   },
   "outputs": [],
   "source": [
    "## 예측값에 대한 임계값을 0.5로 설정하여 0과 1로 구분\n",
    "y_pred_fix = np.where(y_pred>=0.5, 1, 0)\n",
    "y_pred_fix = y_pred_fix.flatten()\n",
    "y_pred_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfeXzbbl6Kpx"
   },
   "outputs": [],
   "source": [
    "len(y_pred_fix.nonzero()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5WwisIM09j8"
   },
   "source": [
    "#### 2) 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-tWfhjh1Aww"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6YAKyea1PcA"
   },
   "outputs": [],
   "source": [
    "## 성능 확인을 위하여 Test set의 Y만 떼와 array로 저장\n",
    "temp = []\n",
    "\n",
    "for te_x, te_y in te_idfd :\n",
    "    temp.append(te_y.numpy())\n",
    "\n",
    "y_true = np.concatenate(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xix8Z2w35916"
   },
   "outputs": [],
   "source": [
    "len(y_true.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2pT6zEw1voT"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred_fix, target_names=['other', 'my']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAfyZM8By-O1"
   },
   "source": [
    "### (3) 모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwLioXUOzHQ3"
   },
   "source": [
    "* **세부 요구사항**\n",
    "    - **반드시 반드시 모델을 저장하고 로컬에 다운로드하세요.**\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcfJldRXy-SB"
   },
   "source": [
    "#### 1) 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkqY7P6Yy-Vn"
   },
   "outputs": [],
   "source": [
    "## .keras로 저장해야 안전\n",
    "custom_model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEvzoc8LzTMM"
   },
   "source": [
    "#### 2) 저장된 모델 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_zGkc_SzS6d"
   },
   "outputs": [],
   "source": [
    "## Colab에 저장된 모델을 불러와 확인\n",
    "temp_model = keras.saving.load_model()\n",
    "temp_model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNvSgjcR1fLKxukaI9Adr18",
   "gpuType": "T4",
   "mount_file_id": "14X1SQnhCehTXTGV_RYHi5i1EHeQGvDj1",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
