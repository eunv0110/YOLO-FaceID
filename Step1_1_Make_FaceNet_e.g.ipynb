{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcionhVJzd5r"
   },
   "source": [
    "# **Make Pretrained-Model FaceNet !**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WE6nWiH8-i9q"
   },
   "source": [
    "## 0.미션\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53bSTpVT-n_Y"
   },
   "source": [
    "### (1) 미션1\n",
    "여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 사전 학습 모델을 만들어야 합니다.\n",
    "\n",
    "그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 만들어야 합니다.\n",
    "\n",
    "- 1) 데이터셋을 불러옵니다.\n",
    "    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n",
    "- 2) 데이터셋을 전처리합니다.\n",
    "    - Keras에는 **실제로 존재하는 이미지 데이터를 처리**해주는 함수가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBjsZP8C-2Ra"
   },
   "source": [
    "### (2) 미션2\n",
    "데이터셋을 **학습에 적합한 형태**로 만들었다면, **FaceNet 모델로 Transfer Learning**을 수행합니다.\n",
    "\n",
    "- 1) FaceNet 모델 구조를 생성합니다.\n",
    "    - [FaceNet 논문 링크](https://arxiv.org/abs/1503.03832)\n",
    "    - FaceNet의 Input은 (160, 160) 사이즈의 이미지입니다.\n",
    "- 2) FaceNet 모델 구조 + 구조 추가\n",
    "    - FaceNet의 Output은 128차원의 벡터입니다.\n",
    "    - 이 과정을 Transfer Learning라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1eYbUCVUoox"
   },
   "source": [
    "### (3) 미션3\n",
    "학습된 모델로 추론하여 성능 지표를 확인하고 모델을 개선시키세요.\n",
    "\n",
    "그 후, 모델의 구조와 가중치를 **반드시 저장**하여 여러분의 노트북에 옮기세요.\n",
    "\n",
    "- 1) 다양한 모델을 사용해보세요.\n",
    "    - 모델에 정해진 정답은 없습니다.\n",
    "    - 성능 지표에서 무엇이 중요한지 깊게 생각하세요.\n",
    "    - 사전 학습된 FaceNet 모델을 사용하셔도 좋고, 아예 독창적으로 여러분만의 모델을 만드셔도 좋습니다!\n",
    "- 2) 모델을 **반드시 저장**하세요.\n",
    "    - .keras 형태로 우선 Colab에 저장하세요.\n",
    "    - Colab에 생성된 .keras 파일을 **로컬에 다운로드** 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkDv7UfdYOgg"
   },
   "source": [
    "## 1.환경설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIxbiQ8wYOcy"
   },
   "source": [
    "* 세부 요구사항\n",
    "    - 경로 설정 : 구글콜랩\n",
    "        * 구글 드라이브 바로 밑에 project4 폴더를 만드세요.\n",
    "        * 데이터 파일을 복사해 넣습니다.\n",
    "        * 필요하다고 판단되는 라이브러리를 추가하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIjpXC-xYHh3"
   },
   "source": [
    "### (1) 경로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6qgvZMSYcoX"
   },
   "source": [
    "* 구글 드라이브 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imfft4dGGJ2E"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPngJ_nwZPRC"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/project4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNEKwf_LY0JB"
   },
   "source": [
    "### (2) 라이브러리 설치 및 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPwDW6e_Y0Fa"
   },
   "source": [
    "* 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4dS7tW-Zwrx"
   },
   "outputs": [],
   "source": [
    "## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n",
    "!pip install keras-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg0gCl9Yatak"
   },
   "source": [
    "## 3.미션1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPvTHwTmbKR5"
   },
   "source": [
    "여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 사전 학습 모델을 만들어야 합니다.\n",
    "\n",
    "그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 만들어야 합니다.\n",
    "\n",
    "- 1) 데이터셋을 불러옵니다.\n",
    "    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n",
    "- 2) 데이터셋을 전처리합니다.\n",
    "    - Keras에는 **실제로 존재하는 이미지 데이터를 처리**해주는 함수가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rXSONrsatd5"
   },
   "source": [
    "### (1) 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXLqxwNaathI"
   },
   "source": [
    "* **세부 요구사항**\n",
    "    - 데이터셋을 불러옵니다.\n",
    "        - 데이터셋은 두 개의 압축 파일이어야 합니다.\n",
    "            1. lfw-deepfunneled.zip : Labeled Faces in the Wild 데이터셋\n",
    "            2. 여러분의 얼굴 이미지 데이터셋\n",
    "                - 여러분의 얼굴 이미지가 담긴 **압축 파일**을 **Google Drive에 업로드** 하기를 권장합니다.\n",
    "                    - 이미지 파일 하나하나 업로드 하면 시간이 오래 걸립니다.\n",
    "    - 데이터셋 압축 파일을 **Colab에 폴더를 생성한 후 해제**하세요.\n",
    "        - 데이터셋 폴더를 **본인 얼굴 폴더, LFW 폴더로 나누어** 생성하는 것을 권장합니다.\n",
    "        - 만일 두 압축 파일을 하나의 폴더에 모두 해제하면 전처리가 더 까다로워질 것입니다.\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - os, zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OntGw5H-C3q"
   },
   "source": [
    "#### 1) 본인 얼굴 이미지 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veax9Lje-CzS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trmm4ozP-C60"
   },
   "outputs": [],
   "source": [
    "data_myFace = os.path.join(path, 'Datasets/Keras/my_face_12000.zip')\n",
    "data_myFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9wNE6-chAih"
   },
   "outputs": [],
   "source": [
    "## Colab에 생성할 본인 얼굴 폴더 경로\n",
    "extract_folder = '/content/my_face'\n",
    "\n",
    "## 위의 경로에 폴더가 없을 때 생성\n",
    "if not os.path.exists(extract_folder) :\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "## 위의 경로에 압축을 해제\n",
    "with zipfile.ZipFile(data_myFace, 'r') as zip_ref :\n",
    "    file_list = zip_ref.namelist()\n",
    "\n",
    "    for f in file_list :\n",
    "        if not f.endswith('/') and f.lower().endswith('.jpg') :\n",
    "            file_name = os.path.basename(f)\n",
    "\n",
    "            if not file_name.startswith('._') :\n",
    "                d_path = os.path.join(extract_folder, file_name)\n",
    "\n",
    "                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n",
    "                    target.write(source.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtpBNHCehXWD"
   },
   "outputs": [],
   "source": [
    "## 생성된 본인 얼굴 이미지 데이터 폴더 안의 이미지 수\n",
    "len(os.listdir(extract_folder) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCDldok5ySsg"
   },
   "source": [
    "#### 2) 다른 얼굴 이미지 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4JpqpxAySpc"
   },
   "outputs": [],
   "source": [
    "data_other = path + '/Keras/lfw-deepfunneled.zip'\n",
    "data_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwRwu_AasZzu"
   },
   "outputs": [],
   "source": [
    "## Colab에 생성할 다른 얼굴 폴더 경로\n",
    "extract_folder = '/content/other_face'\n",
    "\n",
    "## 위의 경로에 폴더가 없을 때 생성\n",
    "if not os.path.exists(extract_folder) :\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "## 위의 경로에 압축을 해제\n",
    "with zipfile.ZipFile(data_other, 'r') as zip_ref :\n",
    "    file_list = zip_ref.namelist()\n",
    "\n",
    "    for f in file_list :\n",
    "        if not f.endswith('/') and f.lower().endswith('.jpg') :\n",
    "            file_name = os.path.basename(f)\n",
    "\n",
    "            if not file_name.startswith('._') :\n",
    "                d_path = os.path.join(extract_folder, file_name)\n",
    "\n",
    "                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n",
    "                    target.write(source.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meIbdjnPySmd"
   },
   "outputs": [],
   "source": [
    "## 생성된 다른 사람 얼굴 이미지 데이터 폴더 안의 이미지 수\n",
    "len(os.listdir(extract_folder) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJxTH37NiCM9"
   },
   "source": [
    "### (2) 데이터셋 전처리\n",
    "* **세부 요구사항**\n",
    "    - 데이터셋을 전처리 합니다.\n",
    "        - Training set, Validation set, Test set으로 데이터셋을 나누어 주세요.\n",
    "            - 학습 과정에서 Training set, Validation set을 사용해야 합니다.\n",
    "            - 추론 과정에서 Test set을 사용해야 합니다.\n",
    "        - Keras의 **특정 함수**가 실제 존재하는 이미지 파일에 대한 전처리를 쉽게 도와줍니다.\n",
    "        - **특정 함수**에서 요구하는 폴더 구조가 있습니다. **특정 함수**를 사용한다면 이에 맞춰서 폴더를 생성해야 합니다.\n",
    "        - 각 데이터셋에 스케일링도 적용하세요.\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - glob, random, shutil, numpy, keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPI-FA1iiPoc"
   },
   "source": [
    "#### 1) 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IINQdzBhUtqV"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtFbWnNZlgtT"
   },
   "outputs": [],
   "source": [
    "## image_dataset_from_directory를 사용하기 위해 Colab에 폴더 생성\n",
    "\n",
    "## 생성될 폴더의 경로\n",
    "tr_data = '/content/tr_data'\n",
    "te_data = '/content/te_data'\n",
    "\n",
    "## 폴더가 존재하지 않을 때 폴더를 생성\n",
    "if not os.path.exists(tr_data) :\n",
    "    os.makedirs(tr_data)\n",
    "\n",
    "if not os.path.exists(te_data) :\n",
    "    os.makedirs(te_data)\n",
    "\n",
    "## 폴더 생성 확인\n",
    "print(os.path.exists(tr_data) )\n",
    "print(os.path.exists(te_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZkhJC1dlgns"
   },
   "outputs": [],
   "source": [
    "## Keras의 image_dataset_from_directory를 사용하기 위해 Colab에 하위 폴더 생성\n",
    "\n",
    "## 생성될 폴더에 대한 하위 폴더 생성\n",
    "class_names = ['my', 'other']\n",
    "\n",
    "for cn in class_names :\n",
    "    temp = os.path.join(tr_data, cn)\n",
    "\n",
    "    if not os.path.exists( temp ) :\n",
    "        os.makedirs(temp)\n",
    "\n",
    "    ## 폴더 생성 확인\n",
    "    print(os.path.exists(temp))\n",
    "\n",
    "for cn in class_names :\n",
    "    temp = os.path.join(te_data, cn)\n",
    "\n",
    "    if not os.path.exists( temp ) :\n",
    "        os.makedirs(temp)\n",
    "\n",
    "    ## 폴더 생성 확인\n",
    "    print(os.path.exists(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QsrKxgXlggh"
   },
   "outputs": [],
   "source": [
    "## 본인 얼굴 데이터가 있는 폴더 경로의 파일 전체를 정렬하여 리스트화\n",
    "img_list_my = sorted(glob.glob('/content/my_face/*',))\n",
    "\n",
    "## 다른 얼굴 데이터가 있는 폴더 경로의 파일 전체를 정렬하여 리스트화\n",
    "img_list_other = sorted(glob.glob('/content/other_face/*'))\n",
    "\n",
    "## 이미지 갯수 확인\n",
    "len(img_list_my), len(img_list_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tu7gBCzOt3j8"
   },
   "outputs": [],
   "source": [
    "## 얼굴 데이터를 Training set, Test set으로 분할하기 위한 사전 작업\n",
    "## 분할 재현성을 위한 난수 고정\n",
    "random.seed(2024)\n",
    "random.shuffle(img_list_my)\n",
    "random.shuffle(img_list_other)\n",
    "\n",
    "img_list_my[:5], img_list_other[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRItB6YgwG__"
   },
   "outputs": [],
   "source": [
    "## Test set의 비율 설정\n",
    "test_size = 0.2\n",
    "\n",
    "## 나의 얼굴 파일 리스트와 다른 얼굴 파일 리스트에 대한 반복문\n",
    "for i_l in [img_list_my, img_list_other] :\n",
    "    ## 리스트의 길이 체크\n",
    "    # list_len = len(i_l)\n",
    "    list_len = 11000  ## 예시 파일의 이미지 갯수가 맞지 않아서 11000개까지만 사용\n",
    "    ## 데이터 분할을 위한 인덱스 설정\n",
    "    split_idx = int(list_len * (1 - test_size) )\n",
    "\n",
    "    ## 인덱스를 이용해 상위 리스트를 Training set, Test set 2가지로 세분화\n",
    "    list_tr = i_l[ : split_idx]\n",
    "    list_te = i_l[split_idx : list_len]\n",
    "\n",
    "    ## 현재 리스트가 나의 얼굴 파일 리스트와 같다면\n",
    "    if i_l == img_list_my :\n",
    "        ## \"나의 얼굴 파일 리스트\"의 파일을 Training set 폴더 안의 \"나의 얼굴 폴더\"로 복사\n",
    "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
    "        for file_path in list_tr :\n",
    "            f_name = file_path.split('/')\n",
    "            shutil.copy(src=file_path,\n",
    "                        dst=tr_data+'/my/'+f_name[-1]\n",
    "                        )\n",
    "            print(f'파일 이동 완료 : {f_name[-1]}')\n",
    "\n",
    "        ## \"나의 얼굴 파일 리스트\"의 파일을 Test set 폴더 안의 \"나의 얼굴 폴더\"로 복사\n",
    "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
    "        for file_path in list_te :\n",
    "            f_name = file_path.split('/')\n",
    "            shutil.copy(src=file_path,\n",
    "                        dst=te_data+'/my/'+f_name[-1]\n",
    "                        )\n",
    "            print(f'파일 이동 완료 : {f_name[-1]}')\n",
    "\n",
    "    ## 현재 리스트가 \"나의 얼굴 파일 리스트\"가 아니라면 (즉, \"다른 사람 얼굴 파일 리스트\"라면)\n",
    "    else :\n",
    "        ## \"다른 사람 얼굴 파일 리스트\"의 파일을 Training set 폴더 안의 \"다른 사람 얼굴 폴더\"로 복사\n",
    "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
    "        for file_path in list_tr :\n",
    "            f_name = file_path.split('/')\n",
    "            shutil.copy(src=file_path,\n",
    "                        dst=tr_data+'/other/'+f_name[-1],\n",
    "                        )\n",
    "            print(f'파일 이동 완료 : {f_name[-1]}')\n",
    "\n",
    "        ## \"다른 사람 얼굴 파일 리스트\"의 파일을 Test set 폴더 안의 \"다른 사람 얼굴 폴더\"로 복사\n",
    "        ## 이동이 잘못 되었을 경우를 생각하여 복사로 진행\n",
    "        for file_path in list_te :\n",
    "            f_name = file_path.split('/')\n",
    "            shutil.copy(src=file_path,\n",
    "                        dst=te_data+'/other/'+f_name[-1]\n",
    "                        )\n",
    "            print(f'파일 이동 완료 : {f_name[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdesufJet3pj"
   },
   "outputs": [],
   "source": [
    "## \"본인 얼굴\"에 대한 파일 리스트의 상위 5개 조회\n",
    "img_list_my[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3nRR3flt3sa"
   },
   "outputs": [],
   "source": [
    "## 위의 5개 파일이 image_dataset_from_directory에 맞춰 생성한 경로에 알맞게 있는지 확인\n",
    "## \"본인 얼굴\"에 대한 파일 리스트를 정렬한 후, 8:2로 나누었기 때문에 위의 상위 5개는 반드시 Training set의 \"나의 얼굴\" 폴더 안에 있어야 한다.\n",
    "\n",
    "print(os.path.exists('/content/tr_data/my/my_face_6786.jpg') )\n",
    "print(os.path.exists('/content/tr_data/my/my_face_2409.jpg') )\n",
    "print(os.path.exists('/content/tr_data/my/my_face_4048.jpg') )\n",
    "print(os.path.exists('/content/tr_data/my/my_face_8427.jpg') )\n",
    "print(os.path.exists('/content/tr_data/my/my_face_2278.jpg') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4xnDKW3twiZ"
   },
   "outputs": [],
   "source": [
    "## 다른 경로에 잘못 복사되었는지 확인\n",
    "\n",
    "print(os.path.exists('/content/tr_data/other/my_face_6786.jpg') )\n",
    "print(os.path.exists('/content/tr_data/other/my_face_2409.jpg') )\n",
    "print(os.path.exists('/content/tr_data/other/my_face_4048.jpg') )\n",
    "print(os.path.exists('/content/tr_data/other/my_face_8427.jpg') )\n",
    "print(os.path.exists('/content/tr_data/other/my_face_2278.jpg') )\n",
    "\n",
    "print(os.path.exists('/content/te_data/my/my_face_6786.jpg') )\n",
    "print(os.path.exists('/content/te_data/my/my_face_2409.jpg') )\n",
    "print(os.path.exists('/content/te_data/my/my_face_4048.jpg') )\n",
    "print(os.path.exists('/content/te_data/my/my_face_8427.jpg') )\n",
    "print(os.path.exists('/content/te_data/my/my_face_2278.jpg') )\n",
    "\n",
    "print(os.path.exists('/content/te_data/other/my_face_6786.jpg') )\n",
    "print(os.path.exists('/content/te_data/other/my_face_2409.jpg') )\n",
    "print(os.path.exists('/content/te_data/other/my_face_4048.jpg') )\n",
    "print(os.path.exists('/content/te_data/other/my_face_8427.jpg') )\n",
    "print(os.path.exists('/content/te_data/other/my_face_2278.jpg') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gLUXyvVt3vG"
   },
   "outputs": [],
   "source": [
    "print('Training data의 my_face 이미지 수 : ', len(os.listdir('/content/tr_data/my')))\n",
    "print('Training data의 other_face 이미지 수 : ', len(os.listdir('/content/tr_data/other')))\n",
    "\n",
    "print('Test data의 my_face 이미지 수 : ', len(os.listdir('/content/te_data/my')))\n",
    "print('Test data의 other_face 이미지 수 : ', len(os.listdir('/content/te_data/other')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbKoJ7sqoGKe"
   },
   "source": [
    "#### 2) **특정 함수** 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2yqpVM0HryP"
   },
   "outputs": [],
   "source": [
    "## Training set 데이터 폴더를 데이터셋화\n",
    "## 이 과정에서 Validation set도 생성\n",
    "tr_idfd, val_idfd = image_dataset_from_directory(tr_data,                    ## Training 폴더 경로\n",
    "                                                 class_names=['other','my'], ## 클래스 순서 지정\n",
    "                                                 batch_size=32,              ## 이미지 덩어리 단위\n",
    "                                                 image_size=(160,160),       ## 이미지 리사이즈\n",
    "                                                 shuffle=True,               ## 섞어야 올바르게 분할됨\n",
    "                                                 seed=2024,                  ## 재현성\n",
    "                                                 validation_split=0.3,       ## 데이터 스플릿 비율\n",
    "                                                 subset='both',              ## 데이터셋 나눔 방식\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvHXK3B-Ij3X"
   },
   "outputs": [],
   "source": [
    "## Test set 데이터 폴더를 데이터셋화\n",
    "te_idfd = image_dataset_from_directory(te_data,                    ## Test 폴더 경로\n",
    "                                       class_names=['other','my'], ## 클래스 순서 지정\n",
    "                                       batch_size=32,              ## 이미지 덩어리 단위\n",
    "                                       image_size=(160,160),       ## 이미지 리사이즈\n",
    "                                       shuffle=True,               ## 섞어야 올바르게 분할됨\n",
    "                                       seed=2024                   ## 재현성\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPafWinHDI6K"
   },
   "outputs": [],
   "source": [
    "## 위에서 만든 이미지 데이터 덩어리가 몇 개인지 확인\n",
    "len(tr_idfd), len(val_idfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pbJTbYA1dN-"
   },
   "source": [
    "#### 3) 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGBzIEeR1fZe"
   },
   "outputs": [],
   "source": [
    "def rescale(image, label) :\n",
    "    image = image / 255\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqM0hsiF3jsi"
   },
   "outputs": [],
   "source": [
    "tr_idfd_rescale = tr_idfd.map(rescale)\n",
    "val_idfd_rescale = val_idfd.map(rescale)\n",
    "te_idfd_rescale = te_idfd.map(rescale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w59u5Dtnrh5h"
   },
   "source": [
    "## 4.미션2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHu91EoOrh2Q"
   },
   "source": [
    "데이터셋을 **학습에 적합한 형태**로 만들었다면, **FaceNet 모델로 Transfer Learning**을 수행합니다.\n",
    "\n",
    "- 1) FaceNet 모델 구조를 생성합니다.\n",
    "    - [FaceNet 논문 링크](https://arxiv.org/abs/1503.03832)\n",
    "    - FaceNet의 Input은 (160, 160) 사이즈의 이미지입니다.\n",
    "- 2) FaceNet 모델 구조 + 구조 추가\n",
    "    - FaceNet의 Output은 128차원의 벡터입니다.\n",
    "    - 이 과정을 Transfer Learning라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEhBeJsarhxh"
   },
   "source": [
    "### (1) FaceNet 구조 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zb-k_TFTsme6"
   },
   "source": [
    "* **세부 요구사항**\n",
    "    - FaceNet의 구조를 생성합니다.\n",
    "        - FaceNet 구조 생성에 필요한 함수를 만듭니다.\n",
    "    - FaceNet의 구조에 **잘 학습된 가중치**를 부여합니다.\n",
    "        - FaceNet 원본 가중치 파일을 공유하였습니다.\n",
    "    - (선택사항) FaceNet 모델의 가중치 업데이트를 방지합니다.\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - numpy, functools, keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jr2hiBBuDL_"
   },
   "source": [
    "#### 1) 모델 구조 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZ3gbjSFyQfK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers import BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers import Lambda, Concatenate, add\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.saving import register_keras_serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33zdBJ9B_qhO"
   },
   "outputs": [],
   "source": [
    "## 3.6.0.dev2024100303 OK\n",
    "## 3.6.0 dev2024101103\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFMvcMGUyQb_"
   },
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "def scaling(x, scale):\n",
    "    return x * scale\n",
    "\n",
    "@register_keras_serializable()\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              strides=1,\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              use_bias=False,\n",
    "              name=None):\n",
    "    x = Conv2D(filters,\n",
    "               kernel_size,\n",
    "               strides=strides,\n",
    "               padding=padding,\n",
    "               use_bias=use_bias,\n",
    "               name=name)(x)\n",
    "    if not use_bias:\n",
    "        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "        bn_name = _generate_layer_name('BatchNorm', prefix=name)\n",
    "        x = BatchNormalization(axis=bn_axis, momentum=0.995, epsilon=0.001,\n",
    "                               scale=False, name=bn_name)(x)\n",
    "    if activation is not None:\n",
    "        ac_name = _generate_layer_name('Activation', prefix=name)\n",
    "        x = Activation(activation, name=ac_name)(x)\n",
    "    return x\n",
    "\n",
    "@register_keras_serializable()\n",
    "def _generate_layer_name(name, branch_idx=None, prefix=None):\n",
    "    if prefix is None:\n",
    "        return None\n",
    "    if branch_idx is None:\n",
    "        return '_'.join((prefix, name))\n",
    "    return '_'.join((prefix, 'Branch', str(branch_idx), name))\n",
    "\n",
    "@register_keras_serializable()\n",
    "def _inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    if block_idx is None:\n",
    "        prefix = None\n",
    "    else:\n",
    "        prefix = '_'.join((block_type, str(block_idx)))\n",
    "    name_fmt = partial(_generate_layer_name, prefix=prefix)\n",
    "\n",
    "    if block_type == 'Block35':\n",
    "        branch_0 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 32, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "        branch_2 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3, name=name_fmt('Conv2d_0c_3x3', 2))\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "    elif block_type == 'Block17':\n",
    "        branch_0 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 128, [1, 7], name=name_fmt('Conv2d_0b_1x7', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 128, [7, 1], name=name_fmt('Conv2d_0c_7x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    elif block_type == 'Block8':\n",
    "        branch_0 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [1, 3], name=name_fmt('Conv2d_0b_1x3', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [3, 1], name=name_fmt('Conv2d_0c_3x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    else:\n",
    "        raise ValueError('Unknown Inception-ResNet block type. '\n",
    "                         'Expects \"Block35\", \"Block17\" or \"Block8\", '\n",
    "                         'but got: ' + str(block_type))\n",
    "\n",
    "    mixed = Concatenate(axis=channel_axis, name=name_fmt('Concatenate'))(branches)\n",
    "    up = conv2d_bn(mixed,\n",
    "                #    K.int_shape(x)[channel_axis],\n",
    "                   x.shape[channel_axis],\n",
    "                   1,\n",
    "                   activation=None,\n",
    "                   use_bias=True,\n",
    "                   name=name_fmt('Conv2d_1x1'))\n",
    "    up = Lambda(scaling,\n",
    "                # output_shape=K.int_shape(up)[1:],\n",
    "                output_shape=up.shape[1:],\n",
    "                arguments={'scale': scale})(up)\n",
    "    x = add([x, up])\n",
    "    if activation is not None:\n",
    "        x = Activation(activation, name=name_fmt('Activation'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgI-eWQgyQZP"
   },
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "def InceptionResNetV1(input_shape=(160, 160, 3),\n",
    "                      classes=128,\n",
    "                      dropout_keep_prob=0.8,\n",
    "                      weights_path=None):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = conv2d_bn(inputs, 32, 3, strides=2, padding='valid', name='Conv2d_1a_3x3')\n",
    "    x = conv2d_bn(x, 32, 3, padding='valid', name='Conv2d_2a_3x3')\n",
    "    x = conv2d_bn(x, 64, 3, name='Conv2d_2b_3x3')\n",
    "    x = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n",
    "    x = conv2d_bn(x, 80, 1, padding='valid', name='Conv2d_3b_1x1')\n",
    "    x = conv2d_bn(x, 192, 3, padding='valid', name='Conv2d_4a_3x3')\n",
    "    x = conv2d_bn(x, 256, 3, strides=2, padding='valid', name='Conv2d_4b_3x3')\n",
    "\n",
    "    # 5x Block35 (Inception-ResNet-A block):\n",
    "    for block_idx in range(1, 6):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.17,\n",
    "                                    block_type='Block35',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 6a (Reduction-A block):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_6a')\n",
    "    branch_0 = conv2d_bn(x,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1, 192, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 2))(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_6a')(branches)\n",
    "\n",
    "    # 10x Block17 (Inception-ResNet-B block):\n",
    "    for block_idx in range(1, 11):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.1,\n",
    "                                    block_type='Block17',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_7a')\n",
    "    branch_0 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 0))\n",
    "    branch_0 = conv2d_bn(branch_0,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_2 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "    branch_2 = conv2d_bn(branch_2,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 2))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 3))(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_7a')(branches)\n",
    "\n",
    "    # 5x Block8 (Inception-ResNet-C block):\n",
    "    for block_idx in range(1, 6):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.2,\n",
    "                                    block_type='Block8',\n",
    "                                    block_idx=block_idx)\n",
    "    x = _inception_resnet_block(x,\n",
    "                                scale=1.,\n",
    "                                activation=None,\n",
    "                                block_type='Block8',\n",
    "                                block_idx=6)\n",
    "\n",
    "    # Classification block\n",
    "    x = GlobalAveragePooling2D(name='AvgPool')(x)\n",
    "    x = Dropout(1.0 - dropout_keep_prob, name='Dropout')(x)\n",
    "    # Bottleneck\n",
    "    x = Dense(classes, use_bias=False, name='Bottleneck')(x)\n",
    "    bn_name = _generate_layer_name('BatchNorm', prefix='Bottleneck')\n",
    "    x = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False,\n",
    "                           name=bn_name)(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs, x, name='inception_resnet_v1')\n",
    "    if weights_path is not None:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPQVI80cyQWK"
   },
   "outputs": [],
   "source": [
    "## FaceNet 구조 생성 코드\n",
    "facenet_model = InceptionResNetV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUtXVTIJugQL"
   },
   "outputs": [],
   "source": [
    "## FaceNet 구조의 전체 레이어 길이\n",
    "len(facenet_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ci_WZVvAyQTM"
   },
   "outputs": [],
   "source": [
    "## FaceNet 전체 구조 확인\n",
    "facenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UfZ2ZjVBKPq"
   },
   "source": [
    "#### 2) 모델에 가중치 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeF72aRXyQQO"
   },
   "outputs": [],
   "source": [
    "## FaceNet 가중치 파일 경로 설정\n",
    "weights_path = os.path.join('Datasets/Keras/facenet_model_weights.npz' )\n",
    "weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xrzp9pu0yQNW"
   },
   "outputs": [],
   "source": [
    "## 가중치 파일 불러오기\n",
    "loaded_weights = np.load(weights_path)\n",
    "\n",
    "loaded_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6p8OaqDQyQKb"
   },
   "outputs": [],
   "source": [
    "## FaceNet 각 레이어에 가중치 적용\n",
    "facenet_model.set_weights([loaded_weights[key] for key in loaded_weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ji08O1bBmU1"
   },
   "source": [
    "#### 3) 모델의 가중치 업데이트 방지 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_HW-n6qory5"
   },
   "outputs": [],
   "source": [
    "## FaceNet 전체 레이어에서 마지막 4개의 레이어 확인\n",
    "facenet_model.layers[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl14ADvFBmRc"
   },
   "outputs": [],
   "source": [
    "## FaceNet 전체 레이어에서 마지막 4개의 레이어에만 가중치 업데이트 적용\n",
    "for l in facenet_model.layers[:-4] :\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSZ6BywVBsES"
   },
   "source": [
    "### (2) 모델 구조 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdRPKS1FwVnp"
   },
   "source": [
    "* **세부 요구사항**\n",
    "    - 우리의 문제에 맞게 모델을 변형해야 합니다.\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj2q7vebwpky"
   },
   "source": [
    "#### 1) 추가 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MflXlU6LBmMV"
   },
   "outputs": [],
   "source": [
    "## FaceNet 모델에 이진 분류용 레이어 하나 추가\n",
    "K.clear_session()\n",
    "\n",
    "custom_model = keras.models.Sequential()\n",
    "\n",
    "custom_model.add(facenet_model)\n",
    "custom_model.add(Dense(1, activation='sigmoid') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDqse1MHx9mC"
   },
   "outputs": [],
   "source": [
    "custom_model.summary() ## keras-nightly로는 정상 작동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROWm9jllAFec"
   },
   "outputs": [],
   "source": [
    "custom_model.compile(optimizer='adam',\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['accuracy', 'precision', 'recall']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCjApw8XxJhT"
   },
   "source": [
    "## 5.미션3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sr5Bh4TCwHbT"
   },
   "source": [
    "학습된 모델로 추론하여 성능 지표를 확인하고 모델을 개선시키세요.\n",
    "\n",
    "그 후, 모델의 구조와 가중치를 **반드시 저장**하여 여러분의 노트북에 옮기세요.\n",
    "\n",
    "- 1) 다양한 모델을 사용해보세요.\n",
    "    - 모델에 정해진 정답은 없습니다.\n",
    "    - 성능 지표에서 무엇이 중요한지 깊게 생각하세요.\n",
    "    - 사전 학습된 FaceNet 모델을 사용하셔도 좋고, 아예 독창적으로 여러분만의 모델을 만드셔도 좋습니다!\n",
    "- 2) 모델을 **반드시 저장**하세요.\n",
    "    - .keras 형태로 우선 Colab에 저장하세요.\n",
    "    - Colab에 생성된 .keras 파일을 **로컬에 다운로드** 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iEtx6mJxaCI"
   },
   "source": [
    "### (1) 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVKBjLf4xeah"
   },
   "source": [
    "* **세부 요구사항**\n",
    "    - 모델 구조를 잘 변형하였다면, 학습도 진행해야 합니다.\n",
    "        - Keras에서 지원하는 다양한 함수를 사용하세요.\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9P5R2_Tp0SGV"
   },
   "source": [
    "#### 1) 학습에 유용한 함수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuOXlSGrxclb"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10XBWir9yCdz"
   },
   "outputs": [],
   "source": [
    "## 얼리스토핑 설정\n",
    "es = EarlyStopping(patience=4, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84-AbpGw0WlD"
   },
   "source": [
    "#### 2) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwyY85hqyC-L"
   },
   "outputs": [],
   "source": [
    "## 모델 학습\n",
    "custom_model.fit(tr_idfd, validation_data=val_idfd,\n",
    "                 epochs=100, verbose=1,\n",
    "                 class_weight={0:1, 1:2}, ## 클래스 1에 대해 가중치를 더 주려는 의도\n",
    "                 callbacks=[es]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsI5xF6ZyDCB"
   },
   "source": [
    "### (2) 모델 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlUaGjUDyDFI"
   },
   "source": [
    "* **세부 요구사항**\n",
    "    - 학습된 모델의 성능을 확인해보세요.\n",
    "        - 임계값 조절, 클래스 가중치 부여 등으로 모델의 성능을 높여보세요.\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - keras, sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUfy6T3-0up8"
   },
   "source": [
    "#### 1) 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adRp8lItyDIJ"
   },
   "outputs": [],
   "source": [
    "## image_dataset_from_directory로 만든 Test set로 예측값 생성\n",
    "y_pred = custom_model.predict(te_idfd)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5enpWwrA2EMa"
   },
   "outputs": [],
   "source": [
    "## 예측값에 대한 임계값을 0.5로 설정하여 0과 1로 구분\n",
    "y_pred_fix = np.where(y_pred>=0.5, 1, 0)\n",
    "y_pred_fix = y_pred_fix.flatten()\n",
    "y_pred_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfeXzbbl6Kpx"
   },
   "outputs": [],
   "source": [
    "len(y_pred_fix.nonzero()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5WwisIM09j8"
   },
   "source": [
    "#### 2) 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-tWfhjh1Aww"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6YAKyea1PcA"
   },
   "outputs": [],
   "source": [
    "## 성능 확인을 위하여 Test set의 Y만 떼와 array로 저장\n",
    "temp = []\n",
    "\n",
    "for te_x, te_y in te_idfd :\n",
    "    temp.append(te_y.numpy())\n",
    "\n",
    "y_true = np.concatenate(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xix8Z2w35916"
   },
   "outputs": [],
   "source": [
    "len(y_true.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2pT6zEw1voT"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred_fix, target_names=['other', 'my']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAfyZM8By-O1"
   },
   "source": [
    "### (3) 모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwLioXUOzHQ3"
   },
   "source": [
    "* **세부 요구사항**\n",
    "    - **반드시 반드시 모델을 저장하고 로컬에 다운로드하세요.**\n",
    "    - 예시 코드에서 사용한 라이브러리\n",
    "        - keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcfJldRXy-SB"
   },
   "source": [
    "#### 1) 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkqY7P6Yy-Vn"
   },
   "outputs": [],
   "source": [
    "## .keras로 저장해야 안전\n",
    "custom_model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEvzoc8LzTMM"
   },
   "source": [
    "#### 2) 저장된 모델 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_zGkc_SzS6d"
   },
   "outputs": [],
   "source": [
    "## Colab에 저장된 모델을 불러와 확인\n",
    "temp_model = keras.saving.load_model()\n",
    "temp_model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNvSgjcR1fLKxukaI9Adr18",
   "gpuType": "T4",
   "mount_file_id": "14X1SQnhCehTXTGV_RYHi5i1EHeQGvDj1",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
